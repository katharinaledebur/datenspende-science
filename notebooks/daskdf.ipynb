{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee968a5f-6d05-46c3-bd33-e80d4862476d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86029d50-10a0-44dd-aa54-82194846d4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install dask_clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d541b21-5edc-410f-8044-89d60a342a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e33c82e-bfcd-4141-8bf6-3d5e6de66580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from datenspende.utils import query_ch_df, query_pg_df\n",
    "import datetime\n",
    "from datetime import date\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e515951a-3f67-4a53-8198-66765ce0f84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ramda as R\n",
    "\n",
    "from os import environ\n",
    "from typing import TypedDict\n",
    "from dask_clickhouse import read_clickhouse\n",
    "from dask.dataframe import DataFrame as dd\n",
    "\n",
    "class DBCredentials(TypedDict):\n",
    "    user: str\n",
    "    password: str\n",
    "    database: str\n",
    "    host: str\n",
    "    port: int\n",
    "    \n",
    "def read_clickhouse_credentials_from_env() -> DBCredentials:\n",
    "    return {\n",
    "        \"user\": environ.get(\"CLICKHOUSE_USER\"),\n",
    "        \"password\": environ.get(\"CLICKHOUSE_PASSWORD\"),\n",
    "        \"database\": environ.get(\"CLICKHOUSE_DB\"),\n",
    "        \"host\": environ.get(\"CLICKHOUSE_HOST\"),\n",
    "        \"port\": int(environ.get(\"CLICKHOUSE_PORT\")),\n",
    "    }\n",
    "\n",
    "def query_dd(query: str) -> dd:\n",
    "    \"\"\"\n",
    "    Read query from clickhouse and return results as dask dataframe.\n",
    "    \n",
    "    Initialize a dask cluster before using this function via\n",
    "    \n",
    "    from dask_gateway import GatewayCluster\n",
    "    cluster = GatewayCluster()\n",
    "    \"\"\"\n",
    "    credentials = read_clickhouse_credentials_from_env()\n",
    "    return read_clickhouse(\n",
    "            query=query,\n",
    "            connection_kwargs=credentials\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1578dd8c-501c-445f-826f-caffd1eaf2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value_types = pd.read_csv('epoch_value_types.csv')\n",
    "value_types = value_types.rename(columns={\"id\": \"type\"})\n",
    "\n",
    "def add_s(st, end):\n",
    "    \n",
    "    if st == end:\n",
    "        end += pd.Timedelta(seconds=1)\n",
    "    return end\n",
    "\n",
    "def clean_endv(st, end):\n",
    "    if end == pd.Timestamp('1970-01-01 00:00:00'):\n",
    "        end = st\n",
    "    return end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90c7014-b75f-4777-959c-7a26d198530e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_epoch(user_ids):\n",
    "     \n",
    "    ft = tuple(user_ids) \n",
    "    q =      \"\"\"SELECT * FROM rocs.vital_data_epoch WHERE vital_data_epoch.customer IN {}\"\"\".format(ft)   \n",
    "    \n",
    "    \n",
    "    us_data = query_dd(q)\n",
    "    us_data = dd.merge(us_data, value_types, on='type')\n",
    "    us_data = us_data.drop(columns=['type'])\n",
    "    us_data = us_data.rename(columns={\"code\": \"type\"})\n",
    "    us_data.startTimestamp = us_data.startTimestamp//1000\n",
    "    us_data.endTimestamp = us_data.endTimestamp//1000\n",
    "    us_data.startTimestamp = us_data.startTimestamp.apply(lambda x: datetime.datetime.fromtimestamp(x),meta=('startTimestamp', 'datetime64[ns]'))\n",
    "    us_data.endTimestamp = us_data.endTimestamp.apply(lambda x: datetime.datetime.fromtimestamp(x),meta=('endTimestamp', 'datetime64[ns]'))\n",
    "    us_data.endTimestamp  = us_data.apply(lambda x: clean_endv(x.startTimestamp, x.endTimestamp),axis=1, meta=(None, 'datetime64[ns]'))\n",
    "    us_data.endTimestamp  = us_data.apply(lambda x: add_s(x.startTimestamp, x.endTimestamp),axis=1, meta=(None, 'datetime64[ns]'))\n",
    "    us_data = us_data.rename(columns={\"startTimestamp\": \"start\", \"endTimestamp\": \"end\"})\n",
    "    us_data = us_data.rename(columns={\"customer\": \"id\"})\n",
    "    \n",
    "    return us_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "448b435b-c49b-4e63-b854-2ce9cc23af7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get age\n",
    "def get_demo(user_ids):\n",
    "    \n",
    "    if isinstance(user_ids, int) or isinstance(user_ids, np.int64):\n",
    "        formatter = f'({user_ids})'\n",
    "    elif len(user_ids) == 1:\n",
    "        formatter = f'({user_ids[0]})'\n",
    "    else:\n",
    "        formatter = tuple(user_ids) \n",
    " \n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        user_id, salutation, birth_date, weight, height, creation_timestamp\n",
    "    FROM \n",
    "        rocs.datenspende.users\n",
    "    WHERE \n",
    "        users.user_id IN {formatter} \n",
    "    \"\"\" \n",
    "\n",
    "    ags = query_pg_df(query)\n",
    "    ags.creation_timestamp = pd.to_datetime(ags['creation_timestamp'],unit='ms') \n",
    "    ags.creation_timestamp = ags.creation_timestamp.dt.date\n",
    "    ags['age'] = np.floor((2023 + 1 / 12) - ags['birth_date'] + 2.5)\n",
    "    \n",
    "    qu = f\"\"\"\n",
    "    select    \n",
    "        a.user_id,\n",
    "        a.created_at,\n",
    "        a.question,\n",
    "        a.element        \n",
    "    from \n",
    "        rocs.datenspende.answers a\n",
    "    where \n",
    "        a.user_id IN {formatter}\n",
    "    AND\n",
    "        a.question = 127    \n",
    "    \"\"\"\n",
    "    sxs = query_pg_df(qu)\n",
    "    sxs.created_at = pd.to_datetime(sxs['created_at'],unit='ms')\n",
    "    sxs.created_at = sxs.created_at.dt.date\n",
    "    \n",
    "    \n",
    "    if len(sxs) > 0:\n",
    "        sex = 'female' if sxs['element'].values[0] == 773 else 'male'\n",
    "    else: \n",
    "        sex = 'nd'\n",
    "    if len(ags) > 0:\n",
    "        age = ags['age'].values[0]\n",
    "    else:\n",
    "        age = 'nd'\n",
    "    \n",
    "    return sex, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20dd1e2b-63cb-4104-9398-2cda6d65f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method takes all the users epoch data and puts it into bin_size_in_min bins of hr / steps data\n",
    "# data explanation\n",
    "# user_data is a dataframe for a single user, single source, HR + steps data\n",
    "# columns\n",
    "# id: user id\n",
    "# longValue: HR in bpm\n",
    "# doubleValue: steps [count]\n",
    "# type: either \"HeartRate\" or \"Steps\"\n",
    "# start: datetime start epoch\n",
    "# end: datetime end epoch\n",
    "# source: data source\n",
    "# \n",
    "#      type source  doubleValue  longValue               id               start                 end\n",
    "# HeartRate Fitbit          NaN       98.0       1234567890 2022-05-28 15:22:26 2022-05-28 15:41:13\n",
    "#     Steps Fitbit       1526.0        NaN       1234567890 2022-05-28 15:22:26 2022-05-28 15:41:13\n",
    "# HeartRate Fitbit          NaN      104.0       1234567890 2022-05-28 17:57:00 2022-05-28 19:31:47\n",
    "#     Steps Fitbit       9269.0        NaN       1234567890 2022-05-28 17:57:00 2022-05-28 19:31:47\n",
    "# HeartRate Fitbit          NaN      105.0       1234567890 2022-05-28 22:15:43 2022-05-28 22:40:30\n",
    "def resample(us_data, bin_size_in_min):\n",
    "    \n",
    "        \n",
    "    if len(us_data.index) > 50:\n",
    "        \n",
    "        user_data = us_data.copy()\n",
    "        user_data = user_data[['id', 'doubleValue', 'longValue', 'booleanValue', 'start', 'end', 'source', 'type']]\n",
    "        user_data = user_data.rename(\n",
    "            columns={\"longValue\": \"hr\", \"doubleValue\": \"steps\", \"booleanValue\": \"sleep\"})\n",
    "        user_data[\"duration\"] = (user_data.end - user_data.start) / pd.Timedelta(\n",
    "            \"1 sec\"\n",
    "        )\n",
    "        user_data = user_data.reset_index(drop=True )\n",
    "        \n",
    "        add_values = user_data[(user_data.duration > 1)&(user_data.type == 'Steps')]\n",
    "\n",
    "        new_values = []\n",
    "        for idx, row in add_values.iterrows():\n",
    "            for i in np.arange(0, row.duration, 1):\n",
    "                end_time = min(\n",
    "                    row.end,\n",
    "                    row.start\n",
    "                    + pd.Timedelta(\"%d sec\" % i)\n",
    "                    + pd.Timedelta(\"%d sec\" % 1),\n",
    "                )\n",
    "                new_duration = (\n",
    "                    end_time - (row.start + pd.Timedelta(\"%d sec\" % i))\n",
    "                ) / pd.Timedelta(\"1 sec\")\n",
    "                new_values.append([\n",
    "                    \n",
    "                    row.id,\n",
    "                    (row.steps / (row.duration / new_duration)),\n",
    "                    row.hr,\n",
    "                    row.sleep,\n",
    "                    row.start + pd.Timedelta(\"%d sec\" % i),\n",
    "                    end_time,\n",
    "                    row.source,\n",
    "                    row.type,\n",
    "                    new_duration,\n",
    "                ])\n",
    "        steps = user_data[(user_data.duration <= 1)&(user_data.type == 'Steps')].append(pd.DataFrame(data=new_values, columns=user_data.columns))\n",
    "        steps = steps.sort_values(by='start')\n",
    "        steps = steps.groupby(['start','type']).mean().reset_index()\n",
    "        \n",
    "        if 'hr' not in steps.columns:\n",
    "            steps['hr'] = np.nan\n",
    "        if 'sleep' not in steps.columns:\n",
    "            steps['sleep'] = np.nan\n",
    "            \n",
    "        df = user_data[user_data.type != 'Steps'].append(steps)\n",
    "        \n",
    "        add_values = df[(df.duration > 60)]\n",
    "\n",
    "        new_values = []\n",
    "        add_values = add_values.fillna(np.nan)\n",
    "        for idx, row in add_values.iterrows():\n",
    "            for i in np.arange(0, row.duration, 60):\n",
    "                end_time = min(\n",
    "                    row.end,\n",
    "                    row.start\n",
    "                    + pd.Timedelta(\"%d sec\" % i)\n",
    "                    + pd.Timedelta(\"%d sec\" % 60),\n",
    "                )\n",
    "                new_duration = (\n",
    "                    end_time - (row.start + pd.Timedelta(\"%d sec\" % i))\n",
    "                ) / pd.Timedelta(\"1 sec\")\n",
    "                new_values.append([\n",
    "                    \n",
    "                    row.id,\n",
    "                    (row.steps / (row.duration / new_duration)),\n",
    "                    row.hr,\n",
    "                    row.sleep,\n",
    "                    row.start + pd.Timedelta(\"%d sec\" % i),\n",
    "                    end_time,\n",
    "                    row.source,\n",
    "                    row.type,\n",
    "                    new_duration,\n",
    "                ])\n",
    "                \n",
    "        df = df[df.duration <= 60].append(pd.DataFrame(data=new_values, columns=user_data.columns))\n",
    "        df = df.sort_values(by='start')\n",
    "        df = df.groupby(['start','type']).mean().reset_index()\n",
    "        \n",
    "        if 'hr' not in df.columns:\n",
    "            df['hr'] = np.nan\n",
    "        if 'sleep' not in df.columns:\n",
    "            df['sleep'] = np.nan\n",
    "        \n",
    "        heartrate_bin = (\n",
    "            df[df.type == \"HeartRate\"][[\"start\", \"hr\"]]\n",
    "            .set_index(\"start\")\n",
    "            .resample(\"%d Min\" % bin_size_in_min)\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        ).dropna(subset=[\"hr\"])\n",
    "        heartrate_bin[\"source\"] = df.source.unique()[0]\n",
    "        heartrate_bin[\"id\"] = df.id.unique()[0]\n",
    "      \n",
    "        restheartrate_bin = (\n",
    "            df[df.type == \"HeartRateRestingHourly\"][[\"start\",  \"hr\"]]\n",
    "            .set_index(\"start\")\n",
    "            .resample(\"%d Min\" % bin_size_in_min)\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        ).dropna(subset=[\"hr\"])\n",
    "       \n",
    "        restheartrate_bin = restheartrate_bin.rename(columns={\"hr\": \"rhr\"})\n",
    "  \n",
    "        sleep_bin = (\n",
    "            df[df.type == \"SleepStateBinary\"][[\"start\",  \"sleep\"]]\n",
    "            .set_index(\"start\")\n",
    "            .resample(\"%d Min\" % bin_size_in_min)\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        ).dropna(subset=[\"sleep\"])\n",
    "\n",
    "        steps_bin = (\n",
    "            df[df.type == \"Steps\"][[\"start\",  \"steps\"]]\n",
    "            .set_index(\"start\")\n",
    "            .resample(\"%d Min\" % bin_size_in_min)\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        ).dropna(subset=[\"steps\"])     \n",
    "\n",
    "        data_frames = [heartrate_bin, restheartrate_bin, sleep_bin, steps_bin]\n",
    "        df_lc = reduce(lambda  left,right: pd.merge(left,right,on=['start'],\n",
    "                                                    how='outer'), data_frames)\n",
    "        return df_lc\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "758cae0a-d66a-4e47-9b6e-461b5d5b9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phases(week):\n",
    "    if week < 0:\n",
    "        ph = 0\n",
    "    elif (week >= 0 and week <= 4):\n",
    "        ph = 1\n",
    "    elif (week >= 5 and week <= 12):\n",
    "        ph = 2\n",
    "    elif week > 12:\n",
    "        ph = 3\n",
    "    return ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de400dd7-4bdc-41ce-8802-5f4fedfe3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test = pd.read_csv('pos_testdate.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca8b68-4ae6-419f-9612-a1e5d23b2d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/datenspende-science/datenspende/utils/load_from_postgres.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n",
      "/home/jovyan/datenspende-science/datenspende/utils/load_from_postgres.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "ud = get_epoch([146789])\n",
    "sex, age = get_demo([146789])\n",
    " \n",
    "if len(ud['source'].unique()) > 1:\n",
    "    # if user has multiple devices, take device with max datapoints\n",
    "    d_len = []\n",
    "    for sour in ud['source'].unique():\n",
    "        d_len.append(len(ud[ud['source'] == sour]))    \n",
    "    ud = ud[ud['source'] == ud['source'].unique()[np.argmax(d_len)]]\n",
    "    user = resample(ud, 15)    \n",
    "else:\n",
    "    user = resample(ud, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b27c8a-49af-453f-ab5d-d72768601503",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "        \n",
    "    user['date'] = user.start.apply(lambda x: x.date())\n",
    "    user['day_of_week'] = pd.to_datetime(user['date']).dt.dayofweek     \n",
    " \n",
    "    user['weekend'] = user['day_of_week'].apply(lambda x: True if x >= 5 else False)\n",
    "\n",
    "    user['dt'] = pd.to_datetime(pos_test['dt'][pos_test['user_id'].isin([us_id])].iloc[0])\n",
    "    user['day_totest'] = pd.to_datetime(user['date']) - user['dt'] \n",
    "    user['week_totest'] = user['day_totest'].apply(lambda x: -(x.days// - 7))\n",
    "    user['phase'] = user['week_totest'].apply(lambda x: phases(x))\n",
    "\n",
    "    if sex == 'female':\n",
    "        MHR = 206 - (0.88 * age)\n",
    "    elif sex == 'male':\n",
    "        MHR = 208 - (0.7 * age)\n",
    "    else:\n",
    "        \n",
    "        MHR = np.nan\n",
    "\n",
    "    user['% of MHR'] = (user['hr'])/ MHR * 100\n",
    "\n",
    "    user.to_csv('user_epoch/'+sex+str(age)+str(us_id)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535cec1-6b83-4632-b225-c71df003be91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b3f4c-82a7-4b5d-b929-2564dcd3675b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "us_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536fbfa-23e0-4967-8a36-367e1d14af9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50820b7d-8fa0-4bc4-a126-f88700adb41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c322030-e91b-4724-92c7-eb7a1a9ba815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (epoch_kl)",
   "language": "python",
   "name": "epoch_kl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
