{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46efe2f4-2b0a-4437-9461-df212b1624d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from datenspende.utils import query_ch_df, query_pg_df\n",
    "import datetime\n",
    "from datetime import date\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67678d07-7a4b-45e1-ac9b-0e8e19c456a4",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215fef31-16d4-4725-8eb1-3fe13000dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all epoch data on user\n",
    "def get_epoch(user_ids):\n",
    "    \n",
    "   \n",
    "    ft = tuple(user_ids)    \n",
    "    df = query_ch_df(\n",
    "            #\"\"\"DESCRIBE TABLE rocs.test_table\"\"\"\n",
    "        #\"\"\"SELECT * FROM rocs.vital_data_epoch WHERE vital_data_epoch.customer IN {formatter}\"\"\"\n",
    "        \"\"\"SELECT * FROM rocs.vital_data_epoch WHERE vital_data_epoch.customer IN {}\"\"\".format(ft) \n",
    "        #\"\"\"SELECT * FROM rocs.vital_data_epoch LIMIT 5000\"\"\"\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c506bef-1db3-470d-b2ff-8c52616e21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get age\n",
    "def get_demo(user_ids):\n",
    "    \n",
    "    if isinstance(user_ids, int) or isinstance(user_ids, np.int64):\n",
    "        formatter = f'({user_ids})'\n",
    "    elif len(user_ids) == 1:\n",
    "        formatter = f'({user_ids[0]})'\n",
    "    else:\n",
    "        formatter = tuple(user_ids) \n",
    "    \n",
    "    \n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        user_id, salutation, birth_date, weight, height, creation_timestamp\n",
    "    FROM \n",
    "        rocs.datenspende.users\n",
    "    WHERE \n",
    "        users.user_id IN {formatter} \n",
    "   \n",
    "    \"\"\" \n",
    "\n",
    "    users = query_pg_df(query)\n",
    "    users.creation_timestamp = pd.to_datetime(users['creation_timestamp'],unit='ms') \n",
    "    users.creation_timestamp = users.creation_timestamp.dt.date\n",
    "    users['age'] = np.floor((2023 + 1 / 12) - users['birth_date'] + 2.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d90b940-108f-415b-a372-74c4a7864fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sex\n",
    "def get_info(user_ids):\n",
    "    \n",
    "    # Make sure that the IN-condition for the SQL query either takes the form '(userid)' in the case\n",
    "    # of a single requested user id or '(userid1, userid2, ..., useridN)' in the case of multiple\n",
    "    # requested user ids\n",
    "    if isinstance(user_ids, int) or isinstance(user_ids, np.int64):\n",
    "        formatter = f'({user_ids})'\n",
    "    elif len(user_ids) == 1:\n",
    "        formatter = f'({user_ids[0]})'\n",
    "    else:\n",
    "        formatter = tuple(user_ids)\n",
    "    \n",
    "    \n",
    "    \n",
    "    qu = f\"\"\"\n",
    "    select\n",
    "        \n",
    "        a.user_id,\n",
    "        a.created_at,\n",
    "        a.question,\n",
    "        a.element\n",
    "        \n",
    "    from \n",
    "        rocs.datenspende.answers a\n",
    "    where \n",
    "        a.user_id IN {formatter}\n",
    "    AND\n",
    "        a.question = 127\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    users = query_pg_df(qu)\n",
    "    users.created_at = pd.to_datetime(users['created_at'],unit='ms')\n",
    "    users.created_at = users.created_at.dt.date\n",
    "    \n",
    "    \n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40055f9b-c34c-4ca3-9baf-470b7252f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_types = pd.read_csv('epoch_value_types.csv')\n",
    "value_types = value_types.rename(columns={\"id\": \"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b27c8a-49af-453f-ab5d-d72768601503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_s(st, end):\n",
    "    \n",
    "    if st == end:\n",
    "        end += pd.Timedelta(seconds=1)\n",
    "    return end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4535cec1-6b83-4632-b225-c71df003be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_endv(st, end):\n",
    "    if end == pd.Timestamp('1970-01-01 00:00:00'):\n",
    "        end = st\n",
    "    return end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d183e57-3c62-4026-b4ca-5445a2071bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify epoch dataframe to get time info and bin in 15 minute intervals\n",
    "def modify_df(user_df):\n",
    "    \n",
    "    user_df = udf.copy()\n",
    "    user_df.startTimestamp = user_df.startTimestamp//1000\n",
    "    user_df.endTimestamp = user_df.endTimestamp//1000\n",
    "    user_df.startTimestamp = user_df.startTimestamp.apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "    user_df.endTimestamp = user_df.endTimestamp.apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "    user_df['date'] = user_df.startTimestamp.apply(lambda x: x.date())\n",
    "    \n",
    "    user_df = user_df.merge(value_types, how='left', on = 'type')\n",
    "    #user_df['entries'] = 1\n",
    "    \n",
    "    user_df['tdelta'] = user_df['endTimestamp'] - user_df['startTimestamp']\n",
    "    user_df['tdelta_min'] = user_df['tdelta'].apply(lambda x: x.total_seconds()//60)\n",
    "    user_df['tdelta_sec'] = user_df['tdelta'].apply(lambda x: x.total_seconds())\n",
    "    user_df['date'] = pd.to_datetime(user_df['date'])\n",
    "    \n",
    "    bins = list(range(0,97))\n",
    "    \n",
    "    \n",
    "    # if end timestamp = 1970-01-01 use start timestamp\n",
    "    # if tdeltasec = 0 add one second\n",
    "    \n",
    "    user_df['endTimestamp'] = user_df.apply(lambda x: clean_endv(x['startTimestamp'], x['endTimestamp']),axis=1)\n",
    "    user_df['endTimestamp'] = user_df.apply(lambda x: add_s(x['startTimestamp'], x['endTimestamp']),axis=1)\n",
    "    \n",
    "    user_df['Interval'] = user_df.apply(lambda x: pd.Interval(x['startTimestamp'],x['endTimestamp'],closed='right'), axis=1)   \n",
    "    \n",
    "    user_df['Time Bin 1'] = pd.cut((user_df.startTimestamp.dt.minute//15) + (user_df.startTimestamp.dt.hour * 4), bins,right=False)\n",
    "    user_df['Time Bin 2'] = pd.cut((user_df.endTimestamp.dt.minute//15) + (user_df.endTimestamp.dt.hour * 4), bins,right=False)\n",
    "    \n",
    "\n",
    "    \n",
    "    return user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7839daea-0eb5-40d8-a53f-8f54bac078e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_overlaps(pdt, vt):\n",
    "    # per day find measurements which were recorded in overlapping time intervals \n",
    "    # combine them by summing up steps and adjusting the interval\n",
    "    # add new entry to df and drop old entries\n",
    "    pdt = pdt.copy()\n",
    "    pdt.index = np.arange(1, len(pdt) + 1)\n",
    "    drop_i = []\n",
    "    cps = []    \n",
    "    for iv in pdt['Interval']:\n",
    "        i = pdt[pdt['Interval'] == iv].index\n",
    "        ov = pdt[pdt['Time Bin 1'] == pdt['Time Bin 1'].loc[i].values[0]].copy()\n",
    "        ov['ov'] = ov['Interval'].apply(lambda x: x.overlaps(iv))\n",
    "        ov = ov[ov['ov']==True]\n",
    "        if len(ov) > 1:\n",
    "            i_min_s = ov[ov['startTimestamp'] == min(ov['startTimestamp'])].index[0]\n",
    "            i_max_e = ov[ov['endTimestamp'] == max(ov['endTimestamp'])].index[0]            \n",
    "            ts = (ov['endTimestamp'].loc[i_min_s] - ov['startTimestamp'].loc[i_min_s]).total_seconds()\n",
    "            \n",
    "            if vt == 'doubleValue':\n",
    "                td = (ov['startTimestamp'].loc[i_max_e]- ov['startTimestamp'].loc[i_min_s]).total_seconds()\n",
    "                f1 = td/ts\n",
    "                comb_val = (f1 * ov[vt].loc[i_min_s]) + ov[vt].loc[i_max_e]\n",
    "                comb_val = comb_val\n",
    "            elif vt == 'longValue':\n",
    "                te = (ov['endTimestamp'].loc[i_max_e]- ov['startTimestamp'].loc[i_max_e]).total_seconds()\n",
    "                tt = (ov['endTimestamp'].loc[i_max_e]- ov['startTimestamp'].loc[i_min_s]).total_seconds()\n",
    "                comb_val = np.average([ov[vt].loc[i_min_s],  ov[vt].loc[i_max_e]], weights=[ts/tt, te/tt])\n",
    "            elif vt == 'booleanValue':\n",
    "                \n",
    "                comb_val = ov[vt].loc[i_min_s]\n",
    "                \n",
    "            cp = ov.iloc[0].copy()\n",
    "            cp[vt] = comb_val\n",
    "            cp['ov'] = False\n",
    "            cp['startTimestamp'] = pd.Timestamp(ov['startTimestamp'].loc[i_min_s])\n",
    "            cp['endTimestamp'] = pd.Timestamp(ov['endTimestamp'].loc[i_max_e])\n",
    "            cp['Interval'] = pd.Interval(cp['startTimestamp'],cp['endTimestamp'],closed='neither')\n",
    "            cp['Time Bin 1'] = ov['Time Bin 1'].loc[i_min_s]\n",
    "            cp['Time Bin 2'] = ov['Time Bin 2'].loc[i_max_e]\n",
    "            #pdt = pdt.drop(ov.index,axis=0)\n",
    "            drop_i.append(ov.index)\n",
    "            cps.append(cp)\n",
    "            \n",
    "            #pdt.loc[len(pdt)+1] = cp\n",
    "            #print(i)\n",
    "           \n",
    "        pdt['ov'] = False\n",
    "    drop_i = list(set(sum([list(a) for a in drop_i], [])))\n",
    "    pdt = pdt.drop(drop_i,axis=0)\n",
    "    for c in cps:\n",
    "        pdt.loc[len(pdt)+1] = c\n",
    "    \n",
    "    return pdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a461507-8d83-4d61-83d8-d96908b337be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for measurements which fall into multiple time bins, calculate fraction of measured steps for each one of the time bins\n",
    "# for every unique time bin create a new row and drop the old one\n",
    "def multiple_bins(i_multiple_bins, dn, time_bins, bin_s, bin_e,vt):\n",
    "    cps = []\n",
    "    for mbi in i_multiple_bins:\n",
    "        mult_bin = dn.loc[mbi].copy()\n",
    "        dn = dn.drop(mbi,axis=0)\n",
    "        # get index of first time bin and last time bin of the multiple time bins to get all bins in between\n",
    "        first_bini = [t for t in range(len(time_bins)) if time_bins[t] == mult_bin['Time Bin 1']][0]\n",
    "        last_bini = [t for t in range(len(time_bins)) if time_bins[t] == mult_bin['Time Bin 2']][0]\n",
    "\n",
    "        t = mult_bin['endTimestamp']-mult_bin['startTimestamp'] # duration of the measurement\n",
    "        for b in range(first_bini, last_bini+1):\n",
    "            cp = mult_bin.copy()\n",
    "\n",
    "            if b == first_bini:\n",
    "                dur = datetime.datetime.combine(datetime.date.min, datetime.datetime.strptime(bin_e[b], '%H:%M:%S').time()) - datetime.datetime.combine(datetime.date.min,  mult_bin['startTimestamp'].time())\n",
    "                if vt == 'doubleValue':\n",
    "                    val = (dur/t) * mult_bin[vt]\n",
    "                elif (vt == 'longValue') or (vt == 'booleanValue'):\n",
    "                    val = mult_bin[vt]\n",
    "                cp['startTimestamp'] = mult_bin['startTimestamp']\n",
    "                cp['endTimestamp'] = cp['startTimestamp'] + dur\n",
    "\n",
    "            elif b == last_bini:\n",
    "                # in order to account for that second (when there are only two time bins the measurement falls into) time bin starts at the same time that first one ends, add one second to duration w factor a\n",
    "                if len(range(first_bini, last_bini+1)) > 2: \n",
    "                    a = datetime.timedelta(seconds=0) \n",
    "                else:\n",
    "                    a = datetime.timedelta(seconds=1)\n",
    "                dur = datetime.datetime.combine(datetime.date.min, mult_bin['endTimestamp'].time() ) - datetime.datetime.combine(datetime.date.min,  datetime.datetime.strptime(bin_s[b], '%H:%M:%S').time())\n",
    "                \n",
    "                if vt == 'doubleValue':\n",
    "                    val = ((dur+a)/t) * mult_bin[vt]\n",
    "                elif (vt == 'longValue') or (vt == 'booleanValue'):\n",
    "                    val = mult_bin[vt]\n",
    "                cp['startTimestamp'] = mult_bin['endTimestamp'] - dur\n",
    "                cp['endTimestamp'] = mult_bin['endTimestamp']\n",
    "            else:\n",
    "                # in order to account for that the n'th (when there are more than two time bins the measurement falls into) time bin starts at the same time that n-1 one ends, add one second to duration w factor a\n",
    "                if len(range(first_bini, last_bini+1)) < 2:\n",
    "                    a = datetime.timedelta(seconds=0)\n",
    "                else:\n",
    "                    a = datetime.timedelta(seconds=1)\n",
    "                bin_st = datetime.datetime.strptime(bin_s[b], '%H:%M:%S').time()\n",
    "                bin_et = datetime.datetime.strptime(bin_e[b], '%H:%M:%S').time() \n",
    "                dur = (datetime.datetime.combine(datetime.date.min, bin_et) - datetime.datetime.combine(datetime.date.min, bin_st ))#+1\n",
    "                if vt == 'doubleValue':\n",
    "                    al = ((dur+a)/t) * mult_bin[vt]\n",
    "                elif (vt == 'longValue') or (vt == 'booleanValue'):\n",
    "                    val = mult_bin[vt]\n",
    "                cp['startTimestamp'] = mult_bin['date'] + datetime.timedelta(hours=bin_st.hour, minutes=bin_st.minute, seconds=bin_st.second)\n",
    "                cp['endTimestamp'] = mult_bin['date'] + datetime.timedelta(hours=bin_et.hour, minutes=bin_et.minute, seconds=bin_et.second)\n",
    "            cp[vt] = val\n",
    "            cp['Time Bin 1'] = time_bins[b]\n",
    "            cp['Time Bin 2'] = time_bins[b]\n",
    "            cp['Interval'] = pd.Interval(cp['startTimestamp'],cp['endTimestamp'],closed='neither')\n",
    "            cps.append(cp)\n",
    "\n",
    "    # append new rows to dataframe\n",
    "    dn.index = np.arange(1, len(dn) + 1)\n",
    "    for c in cps:\n",
    "        dn.loc[len(dn)+1] = c\n",
    "    return dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c220a401-696c-4ca1-a73c-bc93d54c6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get starting and end times of hourly bins\n",
    "bin_s = []\n",
    "bin_e = []\n",
    "for h in range(24):\n",
    "    for m in range(4):\n",
    "    \n",
    "        time_string_s = '%02d:%02d:%02d' % (h,m * 15,0)\n",
    "        time_string_e = '%02d:%02d:%02d' % (h,(m * 15) + 14,59)\n",
    "        bin_s.append(time_string_s)\n",
    "        bin_e.append(time_string_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06d28738-a56a-483e-b98d-54419885fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for steps, hr and sleepstatebinary\n",
    "# one entry per day and time bin\n",
    "# combine with test info \n",
    "def get_df(udf):\n",
    "    \n",
    "    dates = []\n",
    "    tb = []\n",
    "\n",
    "    for d in udf['date'].unique():\n",
    "        for t in time_bins:\n",
    "            dates.append(d)\n",
    "            tb.append(t)\n",
    "            \n",
    "    df_comb = pd.DataFrame(data={'date':dates ,'Time Bin 1':tb})\n",
    "    \n",
    "    for v in [1000, 3000, 2000]:\n",
    "        vt_i = udf[udf['type'] == v]['valueType'].iloc[0]\n",
    "        if vt_i == 0:\n",
    "            vt = 'doubleValue'\n",
    "        elif vt_i == 1:\n",
    "            vt = 'longValue'\n",
    "        elif vt_i == 2:\n",
    "            vt = 'booleanValue'\n",
    "\n",
    "        u_val_df = udf[udf['type'] == v][[vt, 'date', 'code', 'Time Bin 1', 'Time Bin 2', 'Interval','startTimestamp', 'endTimestamp']]\n",
    "        val_code = u_val_df['code'].iloc[0]\n",
    "\n",
    "        pdt_df = []\n",
    "        for date in u_val_df['date'].unique():\n",
    "            pdt_df.append(combine_overlaps(u_val_df[u_val_df['date']==date],vt)) \n",
    "        dn = pd.concat(pdt_df, axis=0)\n",
    "        # re-index\n",
    "        dn.index = np.arange(1, len(dn) + 1)\n",
    "        \n",
    "\n",
    "        if vt_i == 0:\n",
    "            i_multiple_bins = dn[dn['Time Bin 1']!= dn['Time Bin 2']].index\n",
    "            dn = multiple_bins(i_multiple_bins, dn, time_bins, bin_s, bin_e,vt) \n",
    "            dng = dn[['date', 'Time Bin 1',vt]].groupby(['date', 'Time Bin 1']).sum( ).reset_index(level=[0,1])\n",
    "            dng = dng.rename(columns={vt:'steps'})\n",
    "                    \n",
    "            df_comb = pd.merge(df_comb,dng, how='outer', on=['date', 'Time Bin 1'])\n",
    "        \n",
    "        elif vt_i == 1:\n",
    "            \n",
    "            dn['s'] = dn['Interval'].apply(lambda x: x.length.total_seconds())\n",
    "            i_multiple_bins = dn[dn['Time Bin 1']!= dn['Time Bin 2']].index\n",
    "            i_multiple_bins = dn[(dn['Time Bin 1']!= dn['Time Bin 2'])&(dn['s'] != 60)].index\n",
    "            dn = multiple_bins(i_multiple_bins, dn, time_bins, bin_s, bin_e,vt) \n",
    "    \n",
    "            dng = dn[['date', 'Time Bin 1',vt]].groupby(['date', 'Time Bin 1']).mean( ).reset_index(level=[0,1])\n",
    "            dng = dng.rename(columns = {vt:'hr'})         \n",
    "                       \n",
    "            #merge w df above\n",
    "            df_comb = pd.merge(df_comb, dng, how='outer', on=['date', 'Time Bin 1'])\n",
    "            \n",
    "        elif vt_i == 2:\n",
    "            i_multiple_bins = dn[(dn['Time Bin 1']!= dn['Time Bin 2'])].index\n",
    "            dn = multiple_bins(i_multiple_bins, dn, time_bins, bin_s, bin_e,vt) \n",
    "            dng = dn[['date', 'Time Bin 1',vt]].groupby(['date', 'Time Bin 1']).mean( ).reset_index(level=[0,1])\n",
    "            dng = dng.rename(columns = {vt:'sleep'})    \n",
    "            #merge w df above\n",
    "            df_comb = pd.merge(df_comb, dng, how='outer', on=['date', 'Time Bin 1'])\n",
    "    return df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a4cfd0c-e98a-4f05-bb5f-f55af5ea9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phases(week):\n",
    "    if week < 0:\n",
    "        ph = 0\n",
    "    elif (week >= 0 and week <= 4):\n",
    "        ph = 1\n",
    "    elif (week >= 5 and week <= 12):\n",
    "        ph = 2\n",
    "    elif week > 12:\n",
    "        ph = 3\n",
    "    return ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3174191d-2625-4feb-ab65-ba2206b4f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_u = np.load('uid_per_shb_fatigue.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a164dfdb-86bd-425b-84df-f46bdbd3af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test = pd.read_csv('pos_testdate.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed769c-9921-427f-babc-4d78a218fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/datenspende-science/datenspende/utils/load_from_postgres.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n",
      "/home/jovyan/datenspende-science/datenspende/utils/load_from_postgres.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n",
      "/home/jovyan/datenspende-science/datenspende/utils/load_from_postgres.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n",
      "/home/jovyan/datenspende-science/datenspende/utils/load_from_postgres.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n",
      "/home/jovyan/datenspende-science/datenspende/utils/load_from_postgres.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n",
      "/home/jovyan/datenspende-science/datenspende/utils/load_from_postgres.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "for us_id in lc_u:\n",
    "    sex = 'female' if get_info([us_id])['element'].values[0] == 773 else 'male'\n",
    "    age = get_demo([us_id])['age'].values[0]\n",
    "\n",
    "    udf = get_epoch([us_id])\n",
    "    udf = udf.rename(columns={\"customer\": \"user_id\"})\n",
    "    udf = modify_df(udf)\n",
    "    time_bins = sorted(udf['Time Bin 1'].unique())\n",
    "\n",
    "    df_comb = get_df(udf)\n",
    "\n",
    "    df_comb['day_of_week'] = pd.to_datetime(df_comb['date']).dt.dayofweek\n",
    "    df_comb['weekend'] = df_comb['day_of_week'].apply(lambda x: True if x >= 4 else False)\n",
    "\n",
    "    df_comb['dt'] = pd.to_datetime(pos_test['dt'][pos_test['user_id'].isin([us_id])].iloc[0])\n",
    "    td = pd.to_datetime(df_comb['date']) - df_comb['dt'] \n",
    "    df_comb['week_totest'] = td.apply(lambda x: -(x.days// - 7))\n",
    "\n",
    "    df_comb['time'] = df_comb['Time Bin 1'].map(dict(zip(list(df_comb['Time Bin 1'].unique()),list(range(97)))))\n",
    "    df_comb['phase'] = df_comb['week_totest'].apply(lambda x: phases(x))\n",
    "\n",
    "    if sex == 'female':\n",
    "        MAX_HR = 206 - (0.88 * age)\n",
    "    else:\n",
    "        MAX_HR = 208 - (0.7 * age)\n",
    "\n",
    "    df_comb['d to max hr [%]'] = (df_comb['hr'])/ MAX_HR * 100\n",
    "\n",
    "    df_comb.to_csv('user_df/'+sex+str(age)+str(us_id)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a24d66b-4290-40d7-9dcc-4c56177d7221",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'longValue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/datenspende-science/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/datenspende-science/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/datenspende-science/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'longValue'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m i_multiple_bins \u001b[38;5;241m=\u001b[39m dn[(dn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime Bin 1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m dn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime Bin 2\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m&\u001b[39m(dn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m60\u001b[39m)]\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m     44\u001b[0m dn \u001b[38;5;241m=\u001b[39m multiple_bins(i_multiple_bins, dn, time_bins, bin_s, bin_e,vt) \n\u001b[0;32m---> 46\u001b[0m dng \u001b[38;5;241m=\u001b[39m \u001b[43mdn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime Bin 1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     47\u001b[0m dng \u001b[38;5;241m=\u001b[39m dng\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {vt:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr\u001b[39m\u001b[38;5;124m'\u001b[39m})         \n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#merge w df above\u001b[39;00m\n",
      "File \u001b[0;32m~/datenspende-science/.venv/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/datenspende-science/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'longValue'"
     ]
    }
   ],
   "source": [
    "    \n",
    "    dates = []\n",
    "    tb = []\n",
    "\n",
    "    for d in udf['date'].unique():\n",
    "        for t in time_bins:\n",
    "            dates.append(d)\n",
    "            tb.append(t)\n",
    "            \n",
    "    df_comb = pd.DataFrame(data={'date':dates ,'Time Bin 1':tb})\n",
    "    \n",
    "    for v in [1000, 3000, 2000]:\n",
    "        vt_i = udf[udf['type'] == v]['valueType'].iloc[0]\n",
    "        if vt_i == 0:\n",
    "            vt = 'doubleValue'\n",
    "        elif vt_i == 1:\n",
    "            vt = 'longValue'\n",
    "        elif vt_i == 2:\n",
    "            vt = 'booleanValue'\n",
    "\n",
    "        u_val_df = udf[udf['type'] == v][[vt, 'date', 'code', 'Time Bin 1', 'Time Bin 2', 'Interval','startTimestamp', 'endTimestamp']]\n",
    "        val_code = u_val_df['code'].iloc[0]\n",
    "\n",
    "        pdt_df = []\n",
    "        for date in u_val_df['date'].unique():\n",
    "            pdt_df.append(combine_overlaps(u_val_df[u_val_df['date']==date],vt)) \n",
    "        dn = pd.concat(pdt_df, axis=0)\n",
    "        # re-index\n",
    "        dn.index = np.arange(1, len(dn) + 1)\n",
    "        \n",
    "\n",
    "        if vt_i == 0:\n",
    "            i_multiple_bins = dn[dn['Time Bin 1']!= dn['Time Bin 2']].index\n",
    "            dn = multiple_bins(i_multiple_bins, dn, time_bins, bin_s, bin_e,vt) \n",
    "            dng = dn[['date', 'Time Bin 1',vt]].groupby(['date', 'Time Bin 1']).sum( ).reset_index(level=[0,1])\n",
    "            dng = dng.rename(columns={vt:'steps'})\n",
    "                    \n",
    "            df_comb = pd.merge(df_comb,dng, how='outer', on=['date', 'Time Bin 1'])\n",
    "        \n",
    "        elif vt_i == 1:\n",
    "            \n",
    "            dn['s'] = dn['Interval'].apply(lambda x: x.length.total_seconds())\n",
    "            i_multiple_bins = dn[dn['Time Bin 1']!= dn['Time Bin 2']].index\n",
    "            i_multiple_bins = dn[(dn['Time Bin 1']!= dn['Time Bin 2'])&(dn['s'] != 60)].index\n",
    "            dn = multiple_bins(i_multiple_bins, dn, time_bins, bin_s, bin_e,vt) \n",
    "    \n",
    "            dng = dn[['date', 'Time Bin 1',vt]].groupby(['date', 'Time Bin 1']).mean( ).reset_index(level=[0,1])\n",
    "            dng = dng.rename(columns = {vt:'hr'})         \n",
    "                       \n",
    "            #merge w df above\n",
    "            df_comb = pd.merge(df_comb, dng, how='outer', on=['date', 'Time Bin 1'])\n",
    "            \n",
    "        elif vt_i == 2:\n",
    "            i_multiple_bins = dn[(dn['Time Bin 1']!= dn['Time Bin 2'])].index\n",
    "            dn = multiple_bins(i_multiple_bins, dn, time_bins, bin_s, bin_e,vt) \n",
    "            dng = dn[['date', 'Time Bin 1',vt]].groupby(['date', 'Time Bin 1']).mean( ).reset_index(level=[0,1])\n",
    "            dng = dng.rename(columns = {vt:'sleep'})    \n",
    "            #merge w df above\n",
    "            df_comb = pd.merge(df_comb, dng, how='outer', on=['date', 'Time Bin 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e410b5e0-9c12-4df2-8d79-8239d2c6345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longValue</th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>Time Bin 1</th>\n",
       "      <th>Time Bin 2</th>\n",
       "      <th>Interval</th>\n",
       "      <th>startTimestamp</th>\n",
       "      <th>endTimestamp</th>\n",
       "      <th>ov</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[48, 49)</td>\n",
       "      <td>[48, 49)</td>\n",
       "      <td>(2020-12-29 12:04:14, 2020-12-29 12:14:51]</td>\n",
       "      <td>2020-12-29 12:04:14</td>\n",
       "      <td>2020-12-29 12:14:51</td>\n",
       "      <td>False</td>\n",
       "      <td>637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123.0</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[45, 46)</td>\n",
       "      <td>[45, 46)</td>\n",
       "      <td>(2021-05-06 11:16:31, 2021-05-06 11:22:04]</td>\n",
       "      <td>2021-05-06 11:16:31</td>\n",
       "      <td>2021-05-06 11:22:04</td>\n",
       "      <td>False</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.0</td>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[11, 12)</td>\n",
       "      <td>[11, 12)</td>\n",
       "      <td>(2021-09-22 02:46:47, 2021-09-22 02:58:18]</td>\n",
       "      <td>2021-09-22 02:46:47</td>\n",
       "      <td>2021-09-22 02:58:18</td>\n",
       "      <td>False</td>\n",
       "      <td>691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.0</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[14, 15)</td>\n",
       "      <td>[14, 15)</td>\n",
       "      <td>(2021-12-14 03:30:48, 2021-12-14 03:37:52]</td>\n",
       "      <td>2021-12-14 03:30:48</td>\n",
       "      <td>2021-12-14 03:37:52</td>\n",
       "      <td>False</td>\n",
       "      <td>424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98.0</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[11, 12)</td>\n",
       "      <td>[11, 12)</td>\n",
       "      <td>(2022-04-04 02:46:26, 2022-04-04 02:57:06]</td>\n",
       "      <td>2022-04-04 02:46:26</td>\n",
       "      <td>2022-04-04 02:57:06</td>\n",
       "      <td>False</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>103.0</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[14, 15)</td>\n",
       "      <td>[14, 15)</td>\n",
       "      <td>(2022-12-09 03:44:15, 2022-12-09 03:44:59)</td>\n",
       "      <td>2022-12-09 03:44:15</td>\n",
       "      <td>2022-12-09 03:44:59</td>\n",
       "      <td>False</td>\n",
       "      <td>1027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>103.0</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[15, 16)</td>\n",
       "      <td>[15, 16)</td>\n",
       "      <td>(2022-12-09 03:45:00, 2022-12-09 03:59:59)</td>\n",
       "      <td>2022-12-09 03:45:00</td>\n",
       "      <td>2022-12-09 03:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>1027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>103.0</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[16, 17)</td>\n",
       "      <td>[16, 17)</td>\n",
       "      <td>(2022-12-09 04:00:00, 2022-12-09 04:01:22)</td>\n",
       "      <td>2022-12-09 04:00:00</td>\n",
       "      <td>2022-12-09 04:01:22</td>\n",
       "      <td>False</td>\n",
       "      <td>1027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>127.0</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[14, 15)</td>\n",
       "      <td>[14, 15)</td>\n",
       "      <td>(2022-12-12 03:30:56, 2022-12-12 03:44:59)</td>\n",
       "      <td>2022-12-12 03:30:56</td>\n",
       "      <td>2022-12-12 03:44:59</td>\n",
       "      <td>False</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>127.0</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>HeartRate</td>\n",
       "      <td>[15, 16)</td>\n",
       "      <td>[15, 16)</td>\n",
       "      <td>(2022-12-12 03:45:00, 2022-12-12 03:46:13)</td>\n",
       "      <td>2022-12-12 03:45:00</td>\n",
       "      <td>2022-12-12 03:46:13</td>\n",
       "      <td>False</td>\n",
       "      <td>917.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     longValue       date       code Time Bin 1 Time Bin 2  \\\n",
       "1         96.0 2020-12-29  HeartRate   [48, 49)   [48, 49)   \n",
       "2        123.0 2021-05-06  HeartRate   [45, 46)   [45, 46)   \n",
       "3        104.0 2021-09-22  HeartRate   [11, 12)   [11, 12)   \n",
       "4        101.0 2021-12-14  HeartRate   [14, 15)   [14, 15)   \n",
       "5         98.0 2022-04-04  HeartRate   [11, 12)   [11, 12)   \n",
       "...        ...        ...        ...        ...        ...   \n",
       "1956     103.0 2022-12-09  HeartRate   [14, 15)   [14, 15)   \n",
       "1957     103.0 2022-12-09  HeartRate   [15, 16)   [15, 16)   \n",
       "1958     103.0 2022-12-09  HeartRate   [16, 17)   [16, 17)   \n",
       "1959     127.0 2022-12-12  HeartRate   [14, 15)   [14, 15)   \n",
       "1960     127.0 2022-12-12  HeartRate   [15, 16)   [15, 16)   \n",
       "\n",
       "                                        Interval      startTimestamp  \\\n",
       "1     (2020-12-29 12:04:14, 2020-12-29 12:14:51] 2020-12-29 12:04:14   \n",
       "2     (2021-05-06 11:16:31, 2021-05-06 11:22:04] 2021-05-06 11:16:31   \n",
       "3     (2021-09-22 02:46:47, 2021-09-22 02:58:18] 2021-09-22 02:46:47   \n",
       "4     (2021-12-14 03:30:48, 2021-12-14 03:37:52] 2021-12-14 03:30:48   \n",
       "5     (2022-04-04 02:46:26, 2022-04-04 02:57:06] 2022-04-04 02:46:26   \n",
       "...                                          ...                 ...   \n",
       "1956  (2022-12-09 03:44:15, 2022-12-09 03:44:59) 2022-12-09 03:44:15   \n",
       "1957  (2022-12-09 03:45:00, 2022-12-09 03:59:59) 2022-12-09 03:45:00   \n",
       "1958  (2022-12-09 04:00:00, 2022-12-09 04:01:22) 2022-12-09 04:00:00   \n",
       "1959  (2022-12-12 03:30:56, 2022-12-12 03:44:59) 2022-12-12 03:30:56   \n",
       "1960  (2022-12-12 03:45:00, 2022-12-12 03:46:13) 2022-12-12 03:45:00   \n",
       "\n",
       "            endTimestamp     ov       s  \n",
       "1    2020-12-29 12:14:51  False   637.0  \n",
       "2    2021-05-06 11:22:04  False   333.0  \n",
       "3    2021-09-22 02:58:18  False   691.0  \n",
       "4    2021-12-14 03:37:52  False   424.0  \n",
       "5    2022-04-04 02:57:06  False   640.0  \n",
       "...                  ...    ...     ...  \n",
       "1956 2022-12-09 03:44:59  False  1027.0  \n",
       "1957 2022-12-09 03:59:59  False  1027.0  \n",
       "1958 2022-12-09 04:01:22  False  1027.0  \n",
       "1959 2022-12-12 03:44:59  False   917.0  \n",
       "1960 2022-12-12 03:46:13  False   917.0  \n",
       "\n",
       "[1960 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1460aa20-e50f-4304-896e-3802e4ad7c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Time Bin 1</th>\n",
       "      <th>longValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>[60, 61)</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>[61, 62)</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>[62, 63)</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>[57, 58)</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>[58, 59)</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>[14, 15)</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>[15, 16)</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>[16, 17)</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>[14, 15)</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>[15, 16)</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1932 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date Time Bin 1  longValue\n",
       "0    2020-08-03   [60, 61)      102.0\n",
       "1    2020-08-03   [61, 62)      102.0\n",
       "2    2020-08-03   [62, 63)      102.0\n",
       "3    2020-08-04   [57, 58)      118.0\n",
       "4    2020-08-04   [58, 59)      118.0\n",
       "...         ...        ...        ...\n",
       "1927 2022-12-09   [14, 15)      103.0\n",
       "1928 2022-12-09   [15, 16)      103.0\n",
       "1929 2022-12-09   [16, 17)      103.0\n",
       "1930 2022-12-12   [14, 15)      127.0\n",
       "1931 2022-12-12   [15, 16)      127.0\n",
       "\n",
       "[1932 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dn[['date', 'Time Bin 1',vt]].groupby(['date', 'Time Bin 1']).mean( ).reset_index([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db562183-44cf-4053-9944-13dedb075a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51633ec2-6c07-431f-aca6-b473116995eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "df = dfs[1]\n",
    "w = -10\n",
    "plt.plot(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['steps'].values)\n",
    "plt.xticks(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['Time Bin 1'],rotation\n",
    "           =90);\n",
    "w = 0\n",
    "plt.plot(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['steps'].values)\n",
    "plt.xticks(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['Time Bin 1'],rotation\n",
    "           =90);\n",
    "\n",
    "w = 10\n",
    "plt.plot(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['steps'].values)\n",
    "plt.xticks(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['Time Bin 1'],rotation\n",
    "           =90);\n",
    "\n",
    "plt.legend(['-10 w', '0 w', '10 w']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17cd57-00bd-4fbc-981b-92e889b70ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "df = dfs[1]\n",
    "w = -10\n",
    "plt.plot(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['hr'].values)\n",
    "plt.xticks(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['Time Bin 1'],rotation\n",
    "           =90);\n",
    "w = 0\n",
    "plt.plot(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['hr'].values)\n",
    "plt.xticks(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['Time Bin 1'],rotation\n",
    "           =90);\n",
    "\n",
    "w = 10\n",
    "plt.plot(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['hr'].values)\n",
    "plt.xticks(range(len(df[df['week_totest']==w])),df[df['week_totest']==w]['Time Bin 1'],rotation\n",
    "           =90);\n",
    "\n",
    "plt.legend(['-10 w', '0 w', '10 w']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c0b3a-de62-44bb-a34d-eaf381a6c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d753a8-6e7a-402c-8534-69834bf8e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(16,8))\n",
    "u = ['negative user', 'persistent symtpoms user']\n",
    "for i in range(2):\n",
    "    for ph in [0,1,2,3]:\n",
    "        df = dfs[i]\n",
    "        dfph = df[df['phase'] == ph]\n",
    "        dfph_we = dfph[dfph['weekend'] == True]\n",
    "        dfph_wd = dfph[dfph['weekend'] == False]\n",
    "        ax[0,i].errorbar(dfph_we.groupby('time').mean().index, dfph_we.groupby('time').mean()['hr'], yerr=0)\n",
    "        ax[1,i].errorbar(dfph_wd.groupby('time').mean().index, dfph_wd.groupby('time').mean()['hr'], yerr=0)\n",
    "        ax[0,i].set_ylabel('heart rate weekend')\n",
    "        ax[1,i].set_ylabel('heart rate week')\n",
    "        ax[1,i].set_xlabel('time bins')\n",
    "        ax[0,i].set_title(u[i])\n",
    "plt.legend(['pre', 'acute', 'sub-acute', 'post']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b914b81-5a0b-4673-a98e-65bf02367c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "u = ['negative user', 'persistent symtpoms user']\n",
    "for i in range(2):\n",
    "    for ph in [0,1,2,3]:\n",
    "        df = dfs[i]\n",
    "        dfph = df[df['phase'] == ph]\n",
    "        ax[i].errorbar(dfph.groupby('time').mean().index, dfph.groupby('time').mean()['rhr'], yerr=dfph.groupby('time').std()['rhr'])\n",
    "        ax[i].set_title(u[i])\n",
    "plt.legend(['pre', 'acute', 'sub-acute', 'post']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c0dfe-e74c-46c0-86a0-b9b75c23dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "u = ['negative user', 'persistent symtpoms user']\n",
    "for i in range(2):\n",
    "    for ph in [0,1,2,3]:\n",
    "        df = dfs[i]\n",
    "        dfph = df[df['phase'] == ph]\n",
    "        ax[i].errorbar(dfph.groupby('time').mean().index, dfph.groupby('time').mean()['steps_per_s'], yerr=dfph.groupby('time').std()['steps_per_s'])\n",
    "        ax[i].set_title(u[i])\n",
    "plt.legend(['pre', 'acute', 'sub-acute', 'post']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063d664-4cad-43cc-b232-cb5af350edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4, figsize=(16,8))\n",
    "phases = ['pre', 'acute', 'sub-acute', 'post']\n",
    "for ph in [0,1,2,3]:\n",
    "    df = dfs[1]\n",
    "    dfph = df[df['phase'] == ph]\n",
    "    ax[ph].hist(dfph[dfph['sleep'] != 1]['hr'], density = True, histtype='step')\n",
    "    ax[ph].hist(dfph[dfph['sleep'] == 1]['hr'], density = True, histtype='step')\n",
    "    ax[ph].set_title(phases[ph])\n",
    "plt.legend(['day', 'night']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868cbee-56da-428a-9691-79e975e83193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (epoch_kl)",
   "language": "python",
   "name": "epoch_kl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
